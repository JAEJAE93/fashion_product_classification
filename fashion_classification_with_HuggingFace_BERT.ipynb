{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_classification_with_HuggingFace_BERT",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbWiJu28UvJfHhjCJ1z9w3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "540cdb68879e4d04b919e79ab2e15f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4452594a1df94f10aaf68e16531991fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cbe17420217641f7ac8bc5d868a96806",
              "IPY_MODEL_7dd609facd6e41259d428805c509d14c"
            ]
          }
        },
        "4452594a1df94f10aaf68e16531991fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbe17420217641f7ac8bc5d868a96806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b942ce550cf948a685691f62a042153c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36c9c83c01904279b5bf2c9727d4092e"
          }
        },
        "7dd609facd6e41259d428805c509d14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f282a896c2f4406b80fb14ddcfc63bfb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:01&lt;00:00, 819kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e384026f245c47c8804e3ecede92ec21"
          }
        },
        "b942ce550cf948a685691f62a042153c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36c9c83c01904279b5bf2c9727d4092e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f282a896c2f4406b80fb14ddcfc63bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e384026f245c47c8804e3ecede92ec21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44ef83d382d14145bae8d07a3173f3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c599ce7b1774fdcb567d12cf6357433",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c21001b270094fadbc35f4053aa5e100",
              "IPY_MODEL_6c2974a04f2b4e82ae8629eb39426605"
            ]
          }
        },
        "3c599ce7b1774fdcb567d12cf6357433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c21001b270094fadbc35f4053aa5e100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ba960d5821b4c50a24eb1ed5ae65b91",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eedaa5a502e44a2587cc599b7ee9c8e2"
          }
        },
        "6c2974a04f2b4e82ae8629eb39426605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff60de8068404503854f7e1214ba5458",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:01&lt;00:00, 28.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_052aa8c71e1242b095a97fcde8b23e91"
          }
        },
        "9ba960d5821b4c50a24eb1ed5ae65b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eedaa5a502e44a2587cc599b7ee9c8e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff60de8068404503854f7e1214ba5458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "052aa8c71e1242b095a97fcde8b23e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89cea0fcaf9f439ea60dc0815b3a521d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1b10535fb27349e8bfae73aa191e5806",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2b61950d8734ac7bb3118b51f36fce3",
              "IPY_MODEL_0f66132e60b4430d931d8c15f07618b5"
            ]
          }
        },
        "1b10535fb27349e8bfae73aa191e5806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2b61950d8734ac7bb3118b51f36fce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_445b4b1d73024a149d7de0310087e0cb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1961828,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1961828,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02b099cac0054745baba3440f4f83ec0"
          }
        },
        "0f66132e60b4430d931d8c15f07618b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dece892f82044740b04e9fc4b3724690",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 3.75MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a4cb9d37625425a9a788f3fd25d0fc1"
          }
        },
        "445b4b1d73024a149d7de0310087e0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02b099cac0054745baba3440f4f83ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dece892f82044740b04e9fc4b3724690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a4cb9d37625425a9a788f3fd25d0fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb86efd3c61d4c69bb5f67b87ab3f1f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_babdf960f3ba44daa46293191ba21328",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3bf7244bf0944ee9b5444ae09858198",
              "IPY_MODEL_48558bb1862b440fb0e1d7f0380b839c"
            ]
          }
        },
        "babdf960f3ba44daa46293191ba21328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3bf7244bf0944ee9b5444ae09858198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04fba21ff20348068d74a9324f03c651",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7ee26aaa05a48ca9801d4bceeded9d3"
          }
        },
        "48558bb1862b440fb0e1d7f0380b839c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ca1864401ae457cb720f41f00459a03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:28&lt;00:00, 22.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e2a2b31c303419a94269d82843fbb35"
          }
        },
        "04fba21ff20348068d74a9324f03c651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7ee26aaa05a48ca9801d4bceeded9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ca1864401ae457cb720f41f00459a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e2a2b31c303419a94269d82843fbb35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "495dbf2b49a647bc839f31a9a2d474b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f179a027bda4efda56540b7af86f5e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef633117654d4203a8696d16d452b526",
              "IPY_MODEL_923fa57158ef4e098c865259eaa575bf"
            ]
          }
        },
        "0f179a027bda4efda56540b7af86f5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef633117654d4203a8696d16d452b526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f6cae33039049f39dc380ec2ab46356",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bc67876446342d49216d3a311a566dc"
          }
        },
        "923fa57158ef4e098c865259eaa575bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9498f07baac74235b64a1b9cebe287f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:22&lt;00:00, 32.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_055cca29f9b44f2891984d9d13ff9b75"
          }
        },
        "6f6cae33039049f39dc380ec2ab46356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bc67876446342d49216d3a311a566dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9498f07baac74235b64a1b9cebe287f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "055cca29f9b44f2891984d9d13ff9b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAEJAE93/fashion_product_classification/blob/main/fashion_classification_with_HuggingFace_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opJaFOGW8_nJ"
      },
      "source": [
        "# Hugging Face의 트랜스포머 모델을 설치\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nunuPmU29ZOw",
        "outputId": "7662c66e-a6d2-4ff7-c8a2-dc4156beec73"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 31 05:54:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcxTZDaD9kKQ",
        "outputId": "fff4e419-6894-432b-9752-29391fe6fbb4"
      },
      "source": [
        "# Google drive 접근\n",
        "# http://blog.naver.com/PostView.nhn?blogId=skk1991&logNo=221746903289\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')\n",
        "%cd gdrive/MyDrive/'Colab Notebooks'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1jDEnBY9_72"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "Q6QhAqFV97PT",
        "outputId": "6d3c97cf-db7d-4cc6-ae4f-35ef944101f4"
      },
      "source": [
        "data_path = 'fashion_data/'\n",
        "pkl_path = data_path + 'fashion_data.pkl'\n",
        "\n",
        "# pkl load\n",
        "with open(pkl_path, \"rb\") as f:\n",
        "  total_data = pickle.load(f)\n",
        "\n",
        "print(\"total_data: \", total_data.shape)\n",
        "print(\"product category: \", (total_data[\"상품카테고리\"].unique()))\n",
        "total_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_data:  (31614, 3)\n",
            "product category:  ['지갑' '스웨터' '점퍼/아우터' '코트' '자켓' '팬츠' '신발' '티셔츠' '가방' '트렌치 코트' '모자' '드레스'\n",
            " '머플러/마스크' '홀더 및 케이스' '양말' '스카프' '블라우스' '셔츠' '넥타이' '베스트' '스커트' '장갑' '벨트'\n",
            " '주얼리 및 타이핀']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>상품설명</th>\n",
              "      <th>상품카테고리</th>\n",
              "      <th>상품컬러</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>블랙 가죽 골드 퍼피로고 카드지갑</td>\n",
              "      <td>지갑</td>\n",
              "      <td>BLACK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[인기상품 재입고] 오렌지 19FW 리버서블 풀오버 니트</td>\n",
              "      <td>스웨터</td>\n",
              "      <td>NORMAL ORANGE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[셀럽 협찬 주X욱 착용] 머스타드 《가먼트다잉》 실키 후드점퍼</td>\n",
              "      <td>점퍼/아우터</td>\n",
              "      <td>LIGHT YELLOW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그레이 짜임패턴 울캐시미어혼방 니트</td>\n",
              "      <td>스웨터</td>\n",
              "      <td>LIGHT GREY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[LE RIRE] 베이지 단색 울캐시미어혼방 니트</td>\n",
              "      <td>스웨터</td>\n",
              "      <td>NORMAL BEIGE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31609</th>\n",
              "      <td>[ILFORD]블랙 엠보 가죽 베이직 그립백</td>\n",
              "      <td>가방</td>\n",
              "      <td>BLACK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31610</th>\n",
              "      <td>[HUDSON]블랙 가죽 H금속 로고 클러치백(M)</td>\n",
              "      <td>가방</td>\n",
              "      <td>BLACK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31611</th>\n",
              "      <td>[LINDBERG] 블랙 화이트 로고 모던 클러치</td>\n",
              "      <td>지갑</td>\n",
              "      <td>BLACK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31612</th>\n",
              "      <td>블랙 위빙 가죽 장지갑</td>\n",
              "      <td>지갑</td>\n",
              "      <td>BLACK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31613</th>\n",
              "      <td>블랙 퍼피로고 여행용 장지갑</td>\n",
              "      <td>지갑</td>\n",
              "      <td>BLACK</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31614 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      상품설명  상품카테고리           상품컬러\n",
              "0                       블랙 가죽 골드 퍼피로고 카드지갑      지갑          BLACK\n",
              "1          [인기상품 재입고] 오렌지 19FW 리버서블 풀오버 니트     스웨터  NORMAL ORANGE\n",
              "2      [셀럽 협찬 주X욱 착용] 머스타드 《가먼트다잉》 실키 후드점퍼  점퍼/아우터   LIGHT YELLOW\n",
              "3                      그레이 짜임패턴 울캐시미어혼방 니트     스웨터     LIGHT GREY\n",
              "4              [LE RIRE] 베이지 단색 울캐시미어혼방 니트     스웨터   NORMAL BEIGE\n",
              "...                                    ...     ...            ...\n",
              "31609             [ILFORD]블랙 엠보 가죽 베이직 그립백      가방          BLACK\n",
              "31610         [HUDSON]블랙 가죽 H금속 로고 클러치백(M)      가방          BLACK\n",
              "31611          [LINDBERG] 블랙 화이트 로고 모던 클러치      지갑          BLACK\n",
              "31612                         블랙 위빙 가죽 장지갑      지갑          BLACK\n",
              "31613                      블랙 퍼피로고 여행용 장지갑      지갑          BLACK\n",
              "\n",
              "[31614 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iM47gcR9Op2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0U0NyxN763W"
      },
      "source": [
        "def _preprocessing(text):\n",
        "    \"\"\"\n",
        "        input: string\n",
        "        output: string\n",
        "    \"\"\"\n",
        "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'  # E-mail제거\n",
        "    text = re.sub(pattern = pattern, repl = '', string = text)\n",
        "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+'  # URL제거\n",
        "    text = re.sub(pattern = pattern, repl = '', string = text)\n",
        "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
        "    text = re.sub(pattern = pattern, repl = '', string = text)\n",
        "    pattern = '<[^>]*>'  # HTML 태그 제거\n",
        "    text = re.sub(pattern = pattern, repl = '', string = text)\n",
        "    pattern = '[^\\w\\s]'  # 특수기호제거\n",
        "    text = re.sub(pattern = pattern, repl = ' ', string = text)  \n",
        "    text = ' '.join(text.split()) # 2개 이상의 공백 제거\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "-fc1TYIC8SX1",
        "outputId": "01049c4a-c190-4e16-9cee-af537725d118"
      },
      "source": [
        "text_data = total_data[[\"상품설명\", \"상품카테고리\"]]\n",
        "\n",
        "# label encoder\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "label_encoder.fit(text_data[\"상품카테고리\"])\n",
        "text_data[\"상품카테고리\"] = label_encoder.transform(text_data[\"상품카테고리\"])\n",
        "\n",
        "# text preprocessing\n",
        "text_data[\"상품설명\"] = [_preprocessing(x) for x in text_data[\"상품설명\"]]\n",
        "text_data = text_data.reset_index(drop=True)\n",
        "text_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>상품설명</th>\n",
              "      <th>상품카테고리</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>블랙 가죽 골드 퍼피로고 카드지갑</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>인기상품 재입고 오렌지 19fw 리버서블 풀오버 니트</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>셀럽 협찬 주x욱 착용 머스타드 가먼트다잉 실키 후드점퍼</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그레이 짜임패턴 울캐시미어혼방 니트</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>le rire 베이지 단색 울캐시미어혼방 니트</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31609</th>\n",
              "      <td>ilford 블랙 엠보 가죽 베이직 그립백</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31610</th>\n",
              "      <td>hudson 블랙 가죽 h금속 로고 클러치백 m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31611</th>\n",
              "      <td>lindberg 블랙 화이트 로고 모던 클러치</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31612</th>\n",
              "      <td>블랙 위빙 가죽 장지갑</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31613</th>\n",
              "      <td>블랙 퍼피로고 여행용 장지갑</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31614 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  상품설명  상품카테고리\n",
              "0                   블랙 가죽 골드 퍼피로고 카드지갑      18\n",
              "1        인기상품 재입고 오렌지 19fw 리버서블 풀오버 니트       9\n",
              "2      셀럽 협찬 주x욱 착용 머스타드 가먼트다잉 실키 후드점퍼      16\n",
              "3                  그레이 짜임패턴 울캐시미어혼방 니트       9\n",
              "4            le rire 베이지 단색 울캐시미어혼방 니트       9\n",
              "...                                ...     ...\n",
              "31609          ilford 블랙 엠보 가죽 베이직 그립백       0\n",
              "31610       hudson 블랙 가죽 h금속 로고 클러치백 m       0\n",
              "31611        lindberg 블랙 화이트 로고 모던 클러치      18\n",
              "31612                     블랙 위빙 가죽 장지갑      18\n",
              "31613                  블랙 퍼피로고 여행용 장지갑      18\n",
              "\n",
              "[31614 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "Y1EnGvlr9Osx",
        "outputId": "577e3244-e6a2-42b1-b82e-8b4f6c9419d8"
      },
      "source": [
        "product_category = text_data[\"상품카테고리\"].unique()\n",
        "print(\"product_category num: \", len(product_category))\n",
        "print(\"product_category: \", product_category)\n",
        "\n",
        "train, test = train_test_split(text_data, test_size=0.25, random_state=42)\n",
        "print(\"train: \", train.shape)\n",
        "print(\"test: \", test.shape)\n",
        "train"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "product_category num:  24\n",
            "product_category:  [18  9 16 19 14 22 12 21  0 20  4  2  3 23 13 10  7  8  1  5 11 15  6 17]\n",
            "train:  (23710, 2)\n",
            "test:  (7904, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>상품설명</th>\n",
              "      <th>상품카테고리</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4610</th>\n",
              "      <td>그린 컬러배색 모피 퍼코트</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21025</th>\n",
              "      <td>mmlg knit bucket black</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10645</th>\n",
              "      <td>air line a1 블랙 4way 백팩</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22341</th>\n",
              "      <td>네이비 포켓 울 니트베스트</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30799</th>\n",
              "      <td>argyle fringe knit muffler_cream</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29802</th>\n",
              "      <td>lord nermal ls gold</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>블랙 가죽 로고 클러치백</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>그린 꼬르소 이지 스웻</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15795</th>\n",
              "      <td>stripe pattern 네이비 버티컬 스트라이프 울 홑겹 베스트</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23654</th>\n",
              "      <td>그레이 벨티드 울 롱코트</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23710 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        상품설명  상품카테고리\n",
              "4610                          그린 컬러배색 모피 퍼코트      16\n",
              "21025                 mmlg knit bucket black       4\n",
              "10645                 air line a1 블랙 4way 백팩       0\n",
              "22341                         네이비 포켓 울 니트베스트       9\n",
              "30799       argyle fringe knit muffler_cream       3\n",
              "...                                      ...     ...\n",
              "29802                    lord nermal ls gold      21\n",
              "5390                           블랙 가죽 로고 클러치백       0\n",
              "860                             그린 꼬르소 이지 스웻      21\n",
              "15795  stripe pattern 네이비 버티컬 스트라이프 울 홑겹 베스트       9\n",
              "23654                          그레이 벨티드 울 롱코트      19\n",
              "\n",
              "[23710 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYa2yPdO_3I_"
      },
      "source": [
        "# 전처리 - 훈련셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM_5vbrdMbnm"
      },
      "source": [
        "# BERT 입력 형식에 맞게 변환\n",
        "def _get_bert_sentences(sentences):\n",
        "    sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "# 라벨 추출\n",
        "def _get_label(targets, column):\n",
        "    labels = targets[column].values\n",
        "\n",
        "    return labels\n",
        "\n",
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "def _get_tokenized_texts(version, sentences):\n",
        "    tokenizer = BertTokenizer.from_pretrained(version, do_lower_case=False)\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    return tokenizer, tokenized_texts\n",
        "\n",
        "# 토큰화된 문장 숫자로 변경\n",
        "def _get_input_ids(MAX_LEN, tokenizer, tokenized_texts): # MAX_LEN = 입력 토큰의 최대 시퀀스 길이\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    return input_ids\n",
        "\n",
        "# attention mask 얻기\n",
        "def _get_attention_masks(input_ids):\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i > 0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    return attention_masks\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "def _get_torch_tensor(input_ids, labels, attention_masks):\n",
        "    test_inputs = torch.tensor(input_ids)\n",
        "    test_labels = torch.tensor(labels)\n",
        "    test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return test_inputs, test_labels, test_masks"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brynGzny__gA"
      },
      "source": [
        "![대체 텍스트](https://mino-park7.github.io/images/2019/02/bert-input-representation.png)\n",
        "\n",
        "BERT의 입력은 위의 그림과 같은 형식입니다. Classification을 뜻하는 [CLS] 심볼이 제일 앞에 삽입됩니다. 파인튜닝시 출력에서 이 위치의 값을 사용하여 분류를 합니다. [SEP]은 Seperation을 가리키는데, 두 문장을 구분하는 역할을 합니다. 이 예제에서는 문장이 하나이므로 [SEP]도 하나만 넣습니다.\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uXx0o_w9Ovg",
        "outputId": "1ba182be-2d8f-4227-a1c3-f72b0fe7cdb5"
      },
      "source": [
        "# BERT 입력 형식에 맞게 변환\n",
        "sentences = _get_bert_sentences(train[\"상품설명\"])\n",
        "sentences[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] gt19 heritage tee graphics y06819 groovy papaya [SEP]',\n",
              " '[CLS] 홀가먼트 그린 단색 울혼방 긴팔니트 [SEP]',\n",
              " '[CLS] 그린 가죽 닥스로고 심플 카드홀더 [SEP]',\n",
              " '[CLS] 핑크 로고포인트 코튼혼방 루즈핏 맨투맨 [SEP]',\n",
              " '[CLS] 네이비 컬러블록 면 긴팔캐주얼셔츠 [SEP]',\n",
              " '[CLS] gray 히든밴딩 슬림핏 슬랙스 [SEP]',\n",
              " '[CLS] aberdeen modern 블랙 나일론 가죽 혼방 체크로고 백팩 [SEP]',\n",
              " '[CLS] camellia 블랙 하트 스터드 카드홀더 [SEP]',\n",
              " '[CLS] dear puppy 아이보리 가죽 큐빅 퍼피로고 2단 탑지퍼 반지갑 [SEP]',\n",
              " '[CLS] 블랙 러플장식 면 긴팔블라우스 [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGmHWSMv9OyZ",
        "outputId": "3e6ff38d-ca8a-4abc-e099-f493ebd3dc3a"
      },
      "source": [
        "# 라벨 추출\n",
        "labels = _get_label(train, '상품카테고리')\n",
        "labels"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21,  9, 23, ...,  9, 18,  7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "540cdb68879e4d04b919e79ab2e15f56",
            "4452594a1df94f10aaf68e16531991fd",
            "cbe17420217641f7ac8bc5d868a96806",
            "7dd609facd6e41259d428805c509d14c",
            "b942ce550cf948a685691f62a042153c",
            "36c9c83c01904279b5bf2c9727d4092e",
            "f282a896c2f4406b80fb14ddcfc63bfb",
            "e384026f245c47c8804e3ecede92ec21",
            "44ef83d382d14145bae8d07a3173f3f5",
            "3c599ce7b1774fdcb567d12cf6357433",
            "c21001b270094fadbc35f4053aa5e100",
            "6c2974a04f2b4e82ae8629eb39426605",
            "9ba960d5821b4c50a24eb1ed5ae65b91",
            "eedaa5a502e44a2587cc599b7ee9c8e2",
            "ff60de8068404503854f7e1214ba5458",
            "052aa8c71e1242b095a97fcde8b23e91",
            "89cea0fcaf9f439ea60dc0815b3a521d",
            "1b10535fb27349e8bfae73aa191e5806",
            "e2b61950d8734ac7bb3118b51f36fce3",
            "0f66132e60b4430d931d8c15f07618b5",
            "445b4b1d73024a149d7de0310087e0cb",
            "02b099cac0054745baba3440f4f83ec0",
            "dece892f82044740b04e9fc4b3724690",
            "1a4cb9d37625425a9a788f3fd25d0fc1"
          ]
        },
        "id": "wW7ejVPn9O1U",
        "outputId": "4b2fad52-7e10-4b3f-f9f2-66df7e7dfa8e"
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "\n",
        "tokenizer, tokenized_texts = _get_tokenized_texts('bert-base-multilingual-cased', sentences)\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "540cdb68879e4d04b919e79ab2e15f56",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44ef83d382d14145bae8d07a3173f3f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89cea0fcaf9f439ea60dc0815b3a521d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[CLS] gt19 heritage tee graphics y06819 groovy papaya [SEP]\n",
            "['[CLS]', 'g', '##t', '##19', 'heritage', 'tee', 'graphics', 'y', '##0', '##6', '##8', '##19', 'gr', '##oo', '##vy', 'papa', '##ya', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljRQjmmp9O4J",
        "outputId": "0f93bc5f-269a-48fc-8590-9706a5a1a151"
      },
      "source": [
        "input_ids = _get_input_ids(128, tokenizer, tokenized_texts)\n",
        "input_ids[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,   175, 10123, 54055, 39046, 77711, 69712,   193, 10929,\n",
              "       11211, 11396, 54055, 30518, 22659, 15343, 18434, 10679,   102,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qzx3Jg_9O66",
        "outputId": "44244526-8981-4bf5-8e61-1103201bfd39"
      },
      "source": [
        "# 어텐션 마스크 얻기\n",
        "\n",
        "attention_masks = _get_attention_masks(input_ids)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSyiEUn_9O9y",
        "outputId": "2151b47f-b627-431e-9e49-23cf994bdf53"
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels, \n",
        "                                                                                    random_state=42, \n",
        "                                                                                    test_size=0.1)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=42, \n",
        "                                                       test_size=0.1)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "# train\n",
        "train_inputs, train_labels, train_masks = _get_torch_tensor(train_inputs, train_labels, train_masks)\n",
        "# validation\n",
        "validation_inputs, validation_labels, validation_masks = _get_torch_tensor(validation_inputs, validation_labels, validation_masks)\n",
        "\n",
        "print(\"train_inputs: \", train_inputs.shape)\n",
        "print(\"train_labels: \", train_labels.shape)\n",
        "print(\"train_masks: \", train_masks.shape)\n",
        "print()\n",
        "print(\"validation_inputs: \", validation_inputs.shape)\n",
        "print(\"validation_labels: \", validation_labels.shape)\n",
        "print(\"validation_masks: \", validation_masks.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_inputs:  torch.Size([21339, 128])\n",
            "train_labels:  torch.Size([21339])\n",
            "train_masks:  torch.Size([21339, 128])\n",
            "\n",
            "validation_inputs:  torch.Size([2371, 128])\n",
            "validation_labels:  torch.Size([2371])\n",
            "validation_masks:  torch.Size([2371, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcz5qyZXSCst",
        "outputId": "9c4ef28f-f24c-467c-a76d-87aa5f5eaa90"
      },
      "source": [
        "train_inputs"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   101,   9730, 119308,  ...,      0,      0,      0],\n",
              "        [   101,   8924,  56645,  ...,      0,      0,      0],\n",
              "        [   101,    178,  62063,  ...,      0,      0,      0],\n",
              "        ...,\n",
              "        [   101,  13093,  25635,  ...,      0,      0,      0],\n",
              "        [   101,   9993,  41620,  ...,      0,      0,      0],\n",
              "        [   101,   8924,  56645,  ...,      0,      0,      0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97afj9NO9PAz"
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDiHwJ-J_uWh"
      },
      "source": [
        "# 전처리 - 테스트셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4536adt9PDh",
        "outputId": "b1062527-8c95-4ef9-f0ea-d8cf90eb7486"
      },
      "source": [
        "sentences = test['상품설명']\n",
        "print(\"sentences: \", len(sentences))\n",
        "sentences[:10]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentences:  7904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22337                                         와인 스트랩 긴팔원피스\n",
              "9425                                  antigua 블랙 가죽 배색 토트백\n",
              "6503                                      옐로우 자수장식 면 미니스커트\n",
              "4585                                   블루 스트라이프 린넨혼방 반팔티셔츠\n",
              "23489                                     블랙 소가죽 밴딩장식 앵글부츠\n",
              "12141                                       네이비 체크 울혼방 스커트\n",
              "27015                            grlfrnd 블루 데미지장식 면혼방 데님팬츠\n",
              "8678     coco back 오프화이트 남녀공용 코코카피탄 fast dry 세미오버핏 프린트 티셔츠\n",
              "13448                                         그레이 컬러블록 캡모자\n",
              "9311                                    블루 19fw 터틀넥 풀오버 니트\n",
              "Name: 상품설명, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qXnF33J9PGM",
        "outputId": "63fee133-a451-4da6-83e9-acc4c08126cd"
      },
      "source": [
        "# BERT 입력 형식에 맞게 변환\n",
        "sentences = _get_bert_sentences(test[\"상품설명\"])\n",
        "\n",
        "# 라벨 추출\n",
        "labels = _get_label(test, '상품카테고리')\n",
        "\n",
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer, tokenized_texts = _get_tokenized_texts('bert-base-multilingual-cased', sentences)\n",
        "\n",
        "# 토큰화된 문장 숫자로 변경\n",
        "input_ids = _get_input_ids(128, tokenizer, tokenized_texts)\n",
        "\n",
        "# 어텐션 마스크 얻기\n",
        "attention_masks = _get_attention_masks(input_ids)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs, test_labels, test_masks = _get_torch_tensor(input_ids, labels, attention_masks)\n",
        "\n",
        "print(\"test_inputs: \", test_inputs.shape)\n",
        "print(\"test_labels: \", test_labels.shape)\n",
        "print(\"test_masks: \", test_masks.shape)\n",
        "\n",
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_inputs:  torch.Size([7904, 128])\n",
            "test_labels:  torch.Size([7904])\n",
            "test_masks:  torch.Size([7904, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAgDUe_UBOfo"
      },
      "source": [
        "# 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8lTHN6OAM86",
        "outputId": "3c76dc67-5eae-4e49-e989-ada301b97cc3"
      },
      "source": [
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkaZOdZ-AM_h",
        "outputId": "fa5d00f5-cb56-4994-afcd-dd046f6ab954"
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cb86efd3c61d4c69bb5f67b87ab3f1f7",
            "babdf960f3ba44daa46293191ba21328",
            "d3bf7244bf0944ee9b5444ae09858198",
            "48558bb1862b440fb0e1d7f0380b839c",
            "04fba21ff20348068d74a9324f03c651",
            "d7ee26aaa05a48ca9801d4bceeded9d3",
            "3ca1864401ae457cb720f41f00459a03",
            "8e2a2b31c303419a94269d82843fbb35",
            "495dbf2b49a647bc839f31a9a2d474b7",
            "0f179a027bda4efda56540b7af86f5e3",
            "ef633117654d4203a8696d16d452b526",
            "923fa57158ef4e098c865259eaa575bf",
            "6f6cae33039049f39dc380ec2ab46356",
            "8bc67876446342d49216d3a311a566dc",
            "9498f07baac74235b64a1b9cebe287f9",
            "055cca29f9b44f2891984d9d13ff9b75"
          ]
        },
        "id": "Ye9DSX0SANCQ",
        "outputId": "e19eeaea-8f47-478a-cef6-6766d7c9f822"
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(product_category))\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb86efd3c61d4c69bb5f67b87ab3f1f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "495dbf2b49a647bc839f31a9a2d474b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=24, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MSG-AARBlMX"
      },
      "source": [
        "![대체 텍스트](http://mccormickml.com/assets/BERT/padding_and_mask.png)\n",
        "\n",
        "사전훈련된 BERT는 다양한 문제로 전이학습이 가능합니다. 여기서는 위의 그림과 같이 한 문장을 분류하는 방법을 사용합니다. 영화리뷰 문장이 입력으로 들어가면, 긍정/부정으로 구분합니다. 모델의 출력에서 [CLS] 위치인 첫 번째 토큰에 새로운 레이어를 붙여서 파인튜닝을 합니다. Huggning Face는 BertForSequenceClassification() 함수를 제공하기 때문에 쉽게 구현할 수 있습니다.\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ml2jIqjANHr"
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 4\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqW9cg8qB1mp"
      },
      "source": [
        "# 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GUeT7JJByra"
      },
      "source": [
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goxZk6wyClhk"
      },
      "source": [
        "# colab 튕김 방지\n",
        "\n",
        "function ClickConnect() {var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\"); buttons.forEach(function(btn) { btn.click(); }); console.log(\"1분마다 자동 재연결\"); document.querySelector(\"colab-toolbar-button#connect\").click(); } setInterval(ClickConnect,1000*60);\n",
        "\n",
        "https://somjang.tistory.com/entry/Google-Colab-%EC%9E%90%EC%A3%BC%EB%81%8A%EA%B8%B0%EB%8A%94-%EB%9F%B0%ED%83%80%EC%9E%84-%EB%B0%A9%EC%A7%80%ED%95%98%EA%B8%B0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tmrAi82ByuR",
        "outputId": "37453771-c2d5-4fad-b5cf-7b4ec7b81aa1"
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of    667.    Elapsed: 0:11:10.\n",
            "\n",
            "  Average training loss: 0.80\n",
            "  Training epcoh took: 0:14:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "  Validation took: 0:00:35\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of    667.    Elapsed: 0:11:10.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:14:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation took: 0:00:35\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of    667.    Elapsed: 0:11:10.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:14:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:35\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of    667.    Elapsed: 0:11:10.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:14:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:36\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh31rkRziKb7",
        "outputId": "8bea97f9-93ba-48a9-ae40-e4f25ea2ab23"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbert_files\u001b[0m/                                                  \u001b[01;34mfashion_data\u001b[0m/\n",
            "\u001b[01;34mclassification_with_HuggingFace_BERT\u001b[0m/                        Kobert_test.ipynb\n",
            "classification_with_HuggingFace_BERTmodel_state_dict.pt      \u001b[01;34mkorsquad_files\u001b[0m/\n",
            "classification_with_HuggingFace_BERToptimizer_state_dict.pt  \u001b[01;34mpretrained_files\u001b[0m/\n",
            "fashion_classification_with_HuggingFace_BERT                 \u001b[01;34mskt_bert\u001b[0m/\n",
            "fashion_clustering_with_skt_kobert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWzS9-MDiH4l"
      },
      "source": [
        "# 모델 저장\n",
        "# https://tutorials.pytorch.kr/beginner/saving_loading_models.html\n",
        "\n",
        "model_PATH = \"classification_with_HuggingFace_BERT/\"\n",
        "\n",
        "torch.save(model.state_dict(), model_PATH + \"model_state_dict.pt\")\n",
        "torch.save(optimizer.state_dict(), model_PATH + \"optimizer_state_dict.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51tBQVJaB_3L"
      },
      "source": [
        "# 테스트셋 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_hASZy9kUPn"
      },
      "source": [
        "def eval_model(device, model, test_dataloader):\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPGI1ioYk7-f",
        "outputId": "6b067fef-4cb8-489f-b5af-d0967e2eebf8"
      },
      "source": [
        "# load model, optimizer 설정\n",
        "\n",
        "load_model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(product_category))\n",
        "load_model.cuda()\n",
        "\n",
        "# 옵티마이저 설정\n",
        "load_optimizer = AdamW(load_model.parameters(),\n",
        "                       lr = 2e-5, # 학습률,\n",
        "                       eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                       )\n",
        "\n",
        "load_model.load_state_dict(torch.load(model_PATH + \"model_state_dict.pt\"))\n",
        "load_optimizer.load_state_dict(torch.load(model_PATH + \"optimizer_state_dict.pt\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95UPNOHXmEmd",
        "outputId": "cdbd919f-3e21-4baa-860c-0d9bf4fccb82"
      },
      "source": [
        "eval_model(device, load_model, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    247.    Elapsed: 0:00:48.\n",
            "  Batch   200  of    247.    Elapsed: 0:01:36.\n",
            "\n",
            "Accuracy: 0.95\n",
            "Test took: 0:01:59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw6UyMC_Byw-",
        "outputId": "f99ab15e-d804-40d2-b757-e5f82c410fdb"
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    247.    Elapsed: 0:00:48.\n",
            "  Batch   200  of    247.    Elapsed: 0:01:36.\n",
            "\n",
            "Accuracy: 0.95\n",
            "Test took: 0:01:58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9wt5jQtCL8S"
      },
      "source": [
        "# 새로운 문장 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2_QkkOByzk"
      },
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "    # list로 들어옴.\n",
        "    sentences = ''.join(sentences) # list -> str\n",
        "    sentences = _preprocessing(sentences)\n",
        "    sentences = [sentences] # str -> array (list로 바꿔주는게 아니고 []를 사용해서 array로?..)\n",
        "\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "    print(\"tokenized_texts: \", tokenized_texts)\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    \n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks\n",
        "\n",
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 넣음\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "            \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6sXKBjKbHpI",
        "outputId": "4fa1d472-e145-4278-d59f-f175901e4de5"
      },
      "source": [
        "print(\"product category: \", (total_data[\"상품카테고리\"].unique()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "product category:  ['지갑' '스웨터' '점퍼/아우터' '코트' '자켓' '팬츠' '신발' '티셔츠' '가방' '트렌치 코트' '모자' '드레스'\n",
            " '머플러/마스크' '홀더 및 케이스' '양말' '스카프' '블라우스' '셔츠' '넥타이' '베스트' '스커트' '장갑' '벨트'\n",
            " '주얼리 및 타이핀']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9rRGcZoYRVC"
      },
      "source": [
        "def predict_product_category(sent):\n",
        "  logits = test_sentences([sent])\n",
        "  predict_class = np.argmax(logits)\n",
        "  print(\"sent: {0}, predict: {1}\".format(sent, label_encoder.inverse_transform([predict_class])))\n",
        "\n",
        "  return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxn3YFsHp-g-",
        "outputId": "78a89f48-0052-4a77-85b8-601f6d72b14b"
      },
      "source": [
        "# before\n",
        "\n",
        "predict_product_category(\"지오다노 남 MW 테이퍼드 링클프리 110901\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenized_texts:  [['지', '##오', '##다', '##노', '남', 'MW', '테', '##이', '##퍼', '##드', '링', '##클', '##프', '##리', '110', '##90', '##1']]\n",
            "sent: 지오다노 남 MW 테이퍼드 링클프리 110901, predict: ['신발']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoBZTUbap4Pi",
        "outputId": "f4479ef3-cd11-468a-ce33-d9e55f44d12e"
      },
      "source": [
        "# after\n",
        "\n",
        "predict_product_category( \"지오다노 남 MW 테이퍼드 링클프리 110901\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenized_texts:  [['지', '##오', '##다', '##노', '남', 'm', '##w', '테', '##이', '##퍼', '##드', '링', '##클', '##프', '##리', '110', '##90', '##1']]\n",
            "sent: 지오다노 남 MW 테이퍼드 링클프리 110901, predict: ['신발']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny-dv7DgYkLQ",
        "outputId": "e38b3b8f-0d8d-4b1b-e362-e3e337c0eb68"
      },
      "source": [
        "# Naver 쇼핑몰 데이터 분석\n",
        "\n",
        "test_list = [\n",
        "    '크록스 클린 산타 크루즈 컷 로퍼 남성용 202972-4BM',\n",
        "    '발렌시아가 스피드 러너 트레이너 스니커즈 검흰검',\n",
        "    '푸마 x 메종키츠네 랄프심슨70 화이트',\n",
        "    '뉴발란스 남녀공용 런닝화 MR530SH',\n",
        "    '지오다노 남 테이퍼드 슬랙스 110511',\n",
        "    '지오다노 남 MW 테이퍼드 링클프리 110901',\n",
        "    '[아디다스]바시티 봄버 야구점퍼/GE1340',\n",
        "    '[미니멀프로젝트] 미니멀프로젝트 피그먼트 시그니쳐 오버핏 후드집업 MZT106 / 4color w',\n",
        "    '나이키 빅스우시 윈드브레이커 바람막이 검흰 AR3132-010',\n",
        "    '[다이애그널] [29EDITION]_Pretzel puff knit - ivory',\n",
        "    '폴로 여성 울니트 Wool Vneck Sweater',\n",
        "    '나인식스뉴욕 식스뉴욕 96ny 코튼 테리 루즈핏 풀오버 4종',\n",
        "    '스튜디오톰보이 싱글 소매 리본 트랜치코트 9190111029 013',\n",
        "    '로엠 변형 홑겹 트렌치 RMJTA2301A',\n",
        "    '헨리코튼 코튼 린넨 혼방 피그먼트 다잉코트',\n",
        "    '크림 아이보리 화이트 베이지 브라운 카키 그레이 회색 차콜 프렌치 바질 간절기 봄 루즈핏 오버사이즈 나그랑 어깨패드 허리 끈 스트랩 벨트 빅카라 롱 바바리 트렌치 코트 아우터 자켓',\n",
        "    '칼하트 킥플립 백팩 블랙',\n",
        "    '루알리아 미니 피크닉 토트백',\n",
        "    '라코스테 레이디 미니 크로스백 NF2609'\n",
        "]\n",
        "\n",
        "product_logits_list = []\n",
        "\n",
        "for test_sent in test_list:\n",
        "  product_logits = predict_product_category(test_sent)\n",
        "  product_logits_list.append(product_logits.flatten()) # vector값 저장\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenized_texts:  [['크', '##록', '##스', '클', '##린', '산', '##타', '크', '##루', '##즈', '컷', '로', '##퍼', '남', '##성', '##용', '202', '##97', '##2', '4', '##b', '##m']]\n",
            "sent: 크록스 클린 산타 크루즈 컷 로퍼 남성용 202972-4BM, predict: ['신발']\n",
            "\n",
            "tokenized_texts:  [['발', '##렌', '##시아', '##가', '스', '##피', '##드', '러', '##너', '트', '##레', '##이', '##너', '스', '##니', '##커', '##즈', '검', '##흰', '##검']]\n",
            "sent: 발렌시아가 스피드 러너 트레이너 스니커즈 검흰검, predict: ['신발']\n",
            "\n",
            "tokenized_texts:  [['푸', '##마', 'x', '메', '##종', '##키', '##츠', '##네', '랄', '##프', '##심', '##슨', '##70', '화', '##이트']]\n",
            "sent: 푸마 x 메종키츠네 랄프심슨70 화이트, predict: ['신발']\n",
            "\n",
            "tokenized_texts:  [['뉴', '##발', '##란', '##스', '남', '##녀', '##공', '##용', '런', '##닝', '##화', 'm', '##r', '##53', '##0', '##sh']]\n",
            "sent: 뉴발란스 남녀공용 런닝화 MR530SH, predict: ['신발']\n",
            "\n",
            "tokenized_texts:  [['지', '##오', '##다', '##노', '남', '테', '##이', '##퍼', '##드', '슬', '##랙', '##스', '110', '##51', '##1']]\n",
            "sent: 지오다노 남 테이퍼드 슬랙스 110511, predict: ['팬츠']\n",
            "\n",
            "tokenized_texts:  [['지', '##오', '##다', '##노', '남', 'm', '##w', '테', '##이', '##퍼', '##드', '링', '##클', '##프', '##리', '110', '##90', '##1']]\n",
            "sent: 지오다노 남 MW 테이퍼드 링클프리 110901, predict: ['신발']\n",
            "\n",
            "tokenized_texts:  [['아', '##디', '##다', '##스', '바', '##시', '##티', '봄', '##버', '야구', '##점', '##퍼', 'ge', '##13', '##40']]\n",
            "sent: [아디다스]바시티 봄버 야구점퍼/GE1340, predict: ['점퍼/아우터']\n",
            "\n",
            "tokenized_texts:  [['미', '##니', '##멀', '##프', '##로', '##젝', '##트', '미', '##니', '##멀', '##프', '##로', '##젝', '##트', '피', '##그', '##먼', '##트', '시', '##그', '##니', '##쳐', '[UNK]', '후', '##드', '##집', '##업', 'm', '##zt', '##10', '##6', '4', '##color', 'w']]\n",
            "sent: [미니멀프로젝트] 미니멀프로젝트 피그먼트 시그니쳐 오버핏 후드집업 MZT106 / 4color w, predict: ['티셔츠']\n",
            "\n",
            "tokenized_texts:  [['나', '##이', '##키', '빅', '##스', '##우', '##시', '윈', '##드', '##브', '##레', '##이', '##커', '바', '##람', '##막', '##이', '검', '##흰', 'ar', '##31', '##32', '010']]\n",
            "sent: 나이키 빅스우시 윈드브레이커 바람막이 검흰 AR3132-010, predict: ['티셔츠']\n",
            "\n",
            "tokenized_texts:  [['다', '##이', '##애', '##그', '##널', '29', '##edit', '##ion', '_', 'pret', '##zel', 'pu', '##ff', 'kn', '##it', 'i', '##vor', '##y']]\n",
            "sent: [다이애그널] [29EDITION]_Pretzel puff knit - ivory, predict: ['스웨터']\n",
            "\n",
            "tokenized_texts:  [['폴', '##로', '여성', '울', '##니', '##트', 'wo', '##ol', 'v', '##nec', '##k', 's', '##we', '##ater']]\n",
            "sent: 폴로 여성 울니트 Wool Vneck Sweater, predict: ['스웨터']\n",
            "\n",
            "tokenized_texts:  [['나', '##인', '##식', '##스', '##뉴', '##욕', '식', '##스', '##뉴', '##욕', '96', '##ny', '코', '##튼', '테', '##리', '[UNK]', '풀', '##오', '##버', '4', '##종']]\n",
            "sent: 나인식스뉴욕 식스뉴욕 96ny 코튼 테리 루즈핏 풀오버 4종, predict: ['양말']\n",
            "\n",
            "tokenized_texts:  [['스', '##튜', '##디오', '##톰', '##보', '##이', '싱글', '소', '##매', '리', '##본', '트', '##랜', '##치', '##코', '##트', '919', '##01', '##11', '##02', '##9', '013']]\n",
            "sent: 스튜디오톰보이 싱글 소매 리본 트랜치코트 9190111029 013, predict: ['코트']\n",
            "\n",
            "tokenized_texts:  [['로', '##엠', '변', '##형', '[UNK]', '트', '##렌', '##치', 'r', '##m', '##jta', '##23', '##01', '##a']]\n",
            "sent: 로엠 변형 홑겹 트렌치 RMJTA2301A, predict: ['트렌치 코트']\n",
            "\n",
            "tokenized_texts:  [['헨', '##리', '##코', '##튼', '코', '##튼', '린', '##넨', '혼', '##방', '피', '##그', '##먼', '##트', '다', '##잉', '##코', '##트']]\n",
            "sent: 헨리코튼 코튼 린넨 혼방 피그먼트 다잉코트, predict: ['코트']\n",
            "\n",
            "tokenized_texts:  [['크', '##림', '아', '##이', '##보', '##리', '화', '##이트', '베', '##이지', '브', '##라', '##운', '카', '##키', '그', '##레', '##이', '회', '##색', '차', '##콜', '프', '##렌', '##치', '바', '##질', '간', '##절', '##기', '봄', '[UNK]', '오', '##버', '##사', '##이', '##즈', '나', '##그', '##랑', '어', '##깨', '##패', '##드', '허', '##리', '끈', '스', '##트', '##랩', '벨', '##트', '빅', '##카', '##라', '롱', '바', '##바', '##리', '트', '##렌', '##치', '코', '##트', '아', '##우', '##터', '자', '##켓']]\n",
            "sent: 크림 아이보리 화이트 베이지 브라운 카키 그레이 회색 차콜 프렌치 바질 간절기 봄 루즈핏 오버사이즈 나그랑 어깨패드 허리 끈 스트랩 벨트 빅카라 롱 바바리 트렌치 코트 아우터 자켓, predict: ['자켓']\n",
            "\n",
            "tokenized_texts:  [['칼', '##하', '##트', '킥', '##플', '##립', '백', '##팩', '블', '##랙']]\n",
            "sent: 칼하트 킥플립 백팩 블랙, predict: ['가방']\n",
            "\n",
            "tokenized_texts:  [['루', '##알', '##리아', '미', '##니', '피', '##크', '##닉', '토', '##트', '##백']]\n",
            "sent: 루알리아 미니 피크닉 토트백, predict: ['가방']\n",
            "\n",
            "tokenized_texts:  [['라', '##코', '##스', '##테', '레', '##이', '##디', '미', '##니', '크', '##로', '##스', '##백', 'n', '##f', '##26', '##0', '##9']]\n",
            "sent: 라코스테 레이디 미니 크로스백 NF2609, predict: ['가방']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCTJ6OCoXGFe",
        "outputId": "120fadea-22d8-4c66-9c65-742b3a44c058"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "corpus_embeddings = product_logits_list\n",
        "\n",
        "num_clusters = 7\n",
        "clustering_model = KMeans(n_clusters=num_clusters)\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "\n",
        "clustered_sentences = [[] for i in range(num_clusters)]\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    clustered_sentences[cluster_id].append(test_list[sentence_id])\n",
        "\n",
        "for i, cluster in enumerate(clustered_sentences):\n",
        "    print(\"Cluster \", i+1)\n",
        "    print(cluster)\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster  1\n",
            "['[아디다스]바시티 봄버 야구점퍼/GE1340']\n",
            "\n",
            "Cluster  2\n",
            "['푸마 x 메종키츠네 랄프심슨70 화이트', '지오다노 남 테이퍼드 슬랙스 110511', '나인식스뉴욕 식스뉴욕 96ny 코튼 테리 루즈핏 풀오버 4종']\n",
            "\n",
            "Cluster  3\n",
            "['스튜디오톰보이 싱글 소매 리본 트랜치코트 9190111029 013', '로엠 변형 홑겹 트렌치 RMJTA2301A', '헨리코튼 코튼 린넨 혼방 피그먼트 다잉코트', '크림 아이보리 화이트 베이지 브라운 카키 그레이 회색 차콜 프렌치 바질 간절기 봄 루즈핏 오버사이즈 나그랑 어깨패드 허리 끈 스트랩 벨트 빅카라 롱 바바리 트렌치 코트 아우터 자켓']\n",
            "\n",
            "Cluster  4\n",
            "['칼하트 킥플립 백팩 블랙', '루알리아 미니 피크닉 토트백', '라코스테 레이디 미니 크로스백 NF2609']\n",
            "\n",
            "Cluster  5\n",
            "['크록스 클린 산타 크루즈 컷 로퍼 남성용 202972-4BM', '발렌시아가 스피드 러너 트레이너 스니커즈 검흰검', '뉴발란스 남녀공용 런닝화 MR530SH', '지오다노 남 MW 테이퍼드 링클프리 110901']\n",
            "\n",
            "Cluster  6\n",
            "['[다이애그널] [29EDITION]_Pretzel puff knit - ivory', '폴로 여성 울니트 Wool Vneck Sweater']\n",
            "\n",
            "Cluster  7\n",
            "['[미니멀프로젝트] 미니멀프로젝트 피그먼트 시그니쳐 오버핏 후드집업 MZT106 / 4color w', '나이키 빅스우시 윈드브레이커 바람막이 검흰 AR3132-010']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E575PSCzp0r-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naqOkoHnp0uu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq8M9-ZNp0yA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}